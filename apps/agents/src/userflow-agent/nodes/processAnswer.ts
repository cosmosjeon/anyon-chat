import { LangGraphRunnableConfig } from "@langchain/langgraph";
import { UserFlowReturnType, UserFlowState } from "../state";
import { Answer } from "../types";
import { getModelFromConfig } from "../../utils";
import { PROCESS_ANSWER_PROMPT } from "../prompts";
import { updateUserFlowArtifact } from "../utils/templateGenerator";

/**
 * Process Answer Node
 *
 * Processes user's answer to the current question:
 * 1. Extract key information (screens, features, interactions)
 * 2. Update user flow context
 * 3. Determine if follow-up question is needed
 * 4. Update completeness score
 * 5. Progressively update the artifact template
 */
export async function processAnswer(
  state: UserFlowState,
  config: LangGraphRunnableConfig
): Promise<UserFlowReturnType> {
  console.log("[processAnswer] entering");

  const { messages, latestDynamicQuestion, answers, userFlowContext, artifact } = state;

  // Get the last user message (their answer)
  const lastMessage = messages[messages.length - 1];
  if (!lastMessage || lastMessage._getType() !== "human") {
    console.error("[processAnswer] no user message found");
    return { awaitingAnswer: false };
  }

  const userAnswer = lastMessage.content.toString();
  const questionText = latestDynamicQuestion?.questionText || "ì§ˆë¬¸";

  // Create answer record
  const newAnswer: Answer = {
    questionId: latestDynamicQuestion?.id || `q${answers.length + 1}`,
    questionText,
    answer: userAnswer,
    timestamp: new Date(),
  };

  // Use AI to process the answer
  const model = await getModelFromConfig(config);

  const prompt = PROCESS_ANSWER_PROMPT.replace("{question}", questionText).replace(
    "{answer}",
    userAnswer
  );

  try {
    const response = await model.invoke([
      {
        role: "system",
        content:
          "ë‹¹ì‹ ì€ UX ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ë‹µë³€ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ê¼¬ë¦¬ ì§ˆë¬¸ì´ í•„ìš”í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤.",
      },
      { role: "user", content: prompt },
    ]);

    const responseText = response.content.toString();

    // Try to parse JSON response
    let analysisData: any;
    try {
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        analysisData = JSON.parse(jsonMatch[0]);
      } else {
        analysisData = {
          extractedInfo: {},
          needsFollowUp: false,
          completenessScore: 50,
        };
      }
    } catch (parseError) {
      analysisData = {
        extractedInfo: {},
        needsFollowUp: false,
        completenessScore: 50,
      };
    }

    // Update context with extracted info
    const updatedContext = {
      ...userFlowContext,
      ...extractContextFromAnswer(analysisData.extractedInfo, questionText, userAnswer),
    };

    // Update completeness score
    const newCompletenessScore = Math.min(
      100,
      (state.completenessScore || 0) +
        analysisData.completenessScore / (state.maxQuestions || 20)
    );

    // Determine if follow-up is needed
    const needsFollowup = analysisData.needsFollowUp || false;
    const followUpText = needsFollowup
      ? generateFollowUpQuestion(analysisData.followUpReason, userAnswer)
      : undefined;

    // Progressively update the artifact template
    const updatedArtifact = updateProgressiveTemplate(
      artifact,
      updatedContext,
      newCompletenessScore
    );

    console.log("[processAnswer] processed:", {
      extractedInfo: analysisData.extractedInfo,
      needsFollowup,
      completenessScore: newCompletenessScore,
    });

    return {
      answers: [newAnswer],
      userFlowContext: updatedContext,
      completenessScore: newCompletenessScore,
      needsFollowup,
      customQuestionText: followUpText,
      awaitingAnswer: false,
      artifact: updatedArtifact,
      userFlowContent: updatedArtifact?.contents[0].fullMarkdown || state.userFlowContent,
    };
  } catch (error) {
    console.error("[processAnswer] error processing answer:", error);

    // Fallback: just save the answer
    return {
      answers: [newAnswer],
      completenessScore: Math.min(100, (state.completenessScore || 0) + 5),
      awaitingAnswer: false,
    };
  }
}

/**
 * Extract context information from AI analysis
 */
function extractContextFromAnswer(
  extractedInfo: any,
  questionText: string,
  userAnswer: string
): any {
  const context: any = {};

  // Extract screens
  if (extractedInfo.screens && Array.isArray(extractedInfo.screens)) {
    if (questionText.includes("í™”ë©´ ê°œìˆ˜")) {
      context.totalScreens = extractedInfo.screens.length || parseScreenCount(userAnswer);
    } else {
      context.screenList = extractedInfo.screens.map((name: string) => ({
        name,
        purpose: "",
      }));
    }
  }

  // Extract features
  if (extractedInfo.features && Array.isArray(extractedInfo.features)) {
    context.features = extractedInfo.features;
  }

  // Extract interactions
  if (extractedInfo.interactions && Array.isArray(extractedInfo.interactions)) {
    context.interactions = extractedInfo.interactions;
  }

  // Extract specific patterns from answers
  if (questionText.includes("ë¡œê·¸ì¸")) {
    context.loginMethod = userAnswer;
  }

  if (questionText.includes("ë©”ì¸ í™”ë©´") && questionText.includes("ë ˆì´ì•„ì›ƒ")) {
    context.mainScreenLayout = userAnswer;
  }

  if (questionText.includes("ìŠ¤í”Œë˜ì‹œ")) {
    context.splashDuration = userAnswer;
  }

  if (questionText.includes("ê²°ì œ") || questionText.includes("ìœ ë£Œ")) {
    context.hasFreemium = true;
    context.pricingInfo = userAnswer;
  }

  return context;
}

/**
 * Parse screen count from user answer
 */
function parseScreenCount(answer: string): number | undefined {
  const match = answer.match(/(\d+)/);
  return match ? parseInt(match[1], 10) : undefined;
}

/**
 * Generate follow-up question based on reason
 */
function generateFollowUpQuestion(_reason: string, previousAnswer: string): string {
  // Extract mentioned elements that need clarification
  const elements = extractMentionedElements(previousAnswer);

  if (elements.length > 0) {
    const element = elements[0];
    return `"${element}"ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”? (ì˜ˆ: ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”? ì–´ë””ë¡œ ì´ë™í•˜ë‚˜ìš”?)`;
  }

  return `ë°©ê¸ˆ ë‹µë³€í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?`;
}

/**
 * Extract mentioned UI elements for follow-up
 */
function extractMentionedElements(answer: string): string[] {
  const elements: string[] = [];

  // Common UI element patterns
  const patterns = [
    /([ê°€-í£]+)\s*ë²„íŠ¼/g,
    /([ê°€-í£]+)\s*ì•„ì´ì½˜/g,
    /([ê°€-í£]+)\s*í™”ë©´/g,
    /([ê°€-í£]+)\s*ëª¨ë‹¬/g,
    /([ê°€-í£]+)\s*íƒ­/g,
  ];

  for (const pattern of patterns) {
    const matches = answer.matchAll(pattern);
    for (const match of matches) {
      elements.push(match[0]);
    }
  }

  return elements;
}

/**
 * Progressively update artifact template with new info
 */
function updateProgressiveTemplate(
  artifact: any,
  context: any,
  completenessScore: number
): any {
  if (!artifact) return artifact;

  // Get current markdown
  const currentMarkdown = artifact.contents[0].fullMarkdown || "";

  // Update screen list section
  let updatedMarkdown = currentMarkdown;

  if (context.screenList && context.screenList.length > 0) {
    const screenListText = context.screenList
      .map((screen: any, index: number) => `${index + 1}. **${screen.name}**`)
      .join("\n");

    updatedMarkdown = updatedMarkdown.replace(
      /## ğŸ“± í™”ë©´ ëª©ë¡\n\n_ì‘ì„± ì¤‘\.\.\._/,
      `## ğŸ“± í™”ë©´ ëª©ë¡\n\n${screenListText}\n\nì´ ${context.screenList.length}ê°œ í™”ë©´`
    );
  }

  // Update progress percentage
  updatedMarkdown = updatedMarkdown.replace(
    /\*\*ì‘ì„± ì§„í–‰ë„\*\*:\s*\d+%/,
    `**ì‘ì„± ì§„í–‰ë„**: ${Math.round(completenessScore)}%`
  );

  return updateUserFlowArtifact(
    artifact,
    updatedMarkdown,
    undefined,
    undefined,
    completenessScore
  );
}
